{"cells":[{"cell_type":"markdown","metadata":{},"source":["# DocFormer for Image Document Classification"]},{"cell_type":"markdown","metadata":{},"source":["## Installing Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:40:30.263692Z","iopub.status.busy":"2022-11-13T00:40:30.263345Z","iopub.status.idle":"2022-11-13T00:42:02.936101Z","shell.execute_reply":"2022-11-13T00:42:02.934876Z","shell.execute_reply.started":"2022-11-13T00:40:30.263616Z"},"papermill":{"duration":90.582245,"end_time":"2022-11-02T12:05:27.588931","exception":false,"start_time":"2022-11-02T12:03:57.006686","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!pip install -q pytesseract\n","!sudo apt install  -q tesseract-ocr\n","!pip install  -q transformers\n","!pip install  -q pytorch-lightning\n","!pip install  -q einops\n","!pip install  -q tqdm\n","!pip install  -q 'Pillow==7.1.2'\n","!pip install  -q datasets\n","!pip install wandb\n","!pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:02.939558Z","iopub.status.busy":"2022-11-13T00:42:02.939148Z","iopub.status.idle":"2022-11-13T00:42:05.578542Z","shell.execute_reply":"2022-11-13T00:42:05.577288Z","shell.execute_reply.started":"2022-11-13T00:42:02.939517Z"},"papermill":{"duration":3.008408,"end_time":"2022-11-02T12:05:30.605229","exception":false,"start_time":"2022-11-02T12:05:27.596821","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!git clone https://github.com/uakarsh/docformer.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:05.581150Z","iopub.status.busy":"2022-11-13T00:42:05.580732Z","iopub.status.idle":"2022-11-13T00:42:07.721312Z","shell.execute_reply":"2022-11-13T00:42:07.720219Z","shell.execute_reply.started":"2022-11-13T00:42:05.581109Z"},"papermill":{"duration":2.875823,"end_time":"2022-11-02T12:05:33.489461","exception":false,"start_time":"2022-11-02T12:05:30.613638","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import wandb\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","wandb.login(key=secret_value_0)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007953,"end_time":"2022-11-02T12:05:33.507516","exception":false,"start_time":"2022-11-02T12:05:33.499563","status":"completed"},"tags":[]},"source":["## 2. Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:07.725185Z","iopub.status.busy":"2022-11-13T00:42:07.724514Z","iopub.status.idle":"2022-11-13T00:42:10.093027Z","shell.execute_reply":"2022-11-13T00:42:10.091967Z","shell.execute_reply.started":"2022-11-13T00:42:07.725148Z"},"papermill":{"duration":2.522328,"end_time":"2022-11-02T12:05:36.038362","exception":false,"start_time":"2022-11-02T12:05:33.516034","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import warnings\n","warnings.simplefilter(\"ignore\", UserWarning)\n","warnings.simplefilter(\"ignore\", RuntimeWarning)\n","\n","import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset,DataLoader\n","\n","import torch.nn.functional as F\n","import torchvision.models as models\n","\n","## Adding the path of docformer to system path\n","import sys\n","sys.path.append('./docformer/src/docformer/')\n","\n","## Importing the functions from the DocFormer Repo\n","from dataset import create_features\n","from modeling import DocFormerEncoder,ResNetFeatureExtractor,DocFormerEmbeddings,LanguageFeatureExtractor\n","from transformers import BertTokenizerFast"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:10.095442Z","iopub.status.busy":"2022-11-13T00:42:10.094730Z","iopub.status.idle":"2022-11-13T00:42:10.161887Z","shell.execute_reply":"2022-11-13T00:42:10.160758Z","shell.execute_reply.started":"2022-11-13T00:42:10.095402Z"},"papermill":{"duration":0.072941,"end_time":"2022-11-02T12:05:36.119763","exception":false,"start_time":"2022-11-02T12:05:36.046822","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:10.165494Z","iopub.status.busy":"2022-11-13T00:42:10.164685Z","iopub.status.idle":"2022-11-13T00:42:10.173951Z","shell.execute_reply":"2022-11-13T00:42:10.172966Z","shell.execute_reply.started":"2022-11-13T00:42:10.165442Z"},"papermill":{"duration":0.018175,"end_time":"2022-11-02T12:05:36.146294","exception":false,"start_time":"2022-11-02T12:05:36.128119","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["seed = 42\n","target_size = (500, 384)\n","\n","## Setting some hyperparameters\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","## One can change this configuration and try out new combination\n","config = {\n","  \"coordinate_size\": 96,              ## (768/8), 8 for each of the 8 coordinates of x, y\n","  \"hidden_dropout_prob\": 0.6,\n","  \"hidden_size\": 768,\n","  \"image_feature_pool_shape\": [7, 7, 256],\n","  \"intermediate_ff_size_factor\": 4,\n","  \"max_2d_position_embeddings\": 1024,\n","  \"max_position_embeddings\": 128,\n","  \"max_relative_positions\": 8,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 3,\n","  \"pad_token_id\": 0,\n","  \"shape_size\": 96,\n","  \"vocab_size\": 30522,\n","  \"layer_norm_eps\": 1e-12,\n","}"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008055,"end_time":"2022-11-02T12:05:36.162908","exception":false,"start_time":"2022-11-02T12:05:36.154853","status":"completed"},"tags":[]},"source":["## Subset of Data\n","Here, for the purpose of Demo I would be using only 1000 Images per class, and would train the model on it. Definintely for a data hungry model such as transformers, such a small data is not enough, but let us see what are the results on it."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T01:34:39.193719Z","iopub.status.busy":"2022-11-13T01:34:39.193349Z","iopub.status.idle":"2022-11-13T01:34:39.308168Z","shell.execute_reply":"2022-11-13T01:34:39.307255Z","shell.execute_reply.started":"2022-11-13T01:34:39.193688Z"},"papermill":{"duration":6.808518,"end_time":"2022-11-02T12:05:42.979722","exception":false,"start_time":"2022-11-02T12:05:36.171204","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","\n","## For the purpose of prediction\n","id2label = []\n","label2id = {}\n","\n","curr_class = 0\n","## Preparing the Dataset\n","base_directory = '../input/rvl-cdip-small/data'\n","dict_of_img_labels = {'img':[], 'label':[]}\n","\n","max_sample_per_class = 1000\n","\n","for label in tqdm(os.listdir(base_directory)):\n","    img_path = os.path.join(base_directory, label)\n","    \n","    count = 0\n","    if label not in label2id:\n","        label2id[label] = curr_class\n","        curr_class+=1\n","        id2label.append(label)\n","        \n","    for img in os.listdir(img_path):\n","        if count>max_sample_per_class:\n","            break\n","            \n","        curr_img_path = os.path.join(img_path, img)\n","        dict_of_img_labels['img'].append(curr_img_path)\n","        dict_of_img_labels['label'].append(label2id[label])\n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:11.870934Z","iopub.status.busy":"2022-11-13T00:42:11.870279Z","iopub.status.idle":"2022-11-13T00:42:11.886752Z","shell.execute_reply":"2022-11-13T00:42:11.885901Z","shell.execute_reply.started":"2022-11-13T00:42:11.870895Z"},"papermill":{"duration":0.02212,"end_time":"2022-11-02T12:05:43.010674","exception":false,"start_time":"2022-11-02T12:05:42.988554","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pandas as pd\n","df = pd.DataFrame(dict_of_img_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:11.888655Z","iopub.status.busy":"2022-11-13T00:42:11.888296Z","iopub.status.idle":"2022-11-13T00:42:12.294857Z","shell.execute_reply":"2022-11-13T00:42:12.293856Z","shell.execute_reply.started":"2022-11-13T00:42:11.888620Z"},"papermill":{"duration":0.822518,"end_time":"2022-11-02T12:05:43.841380","exception":false,"start_time":"2022-11-02T12:05:43.018862","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split as tts\n","train_df, valid_df = tts(df, random_state = seed, stratify = df['label'], shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:12.299415Z","iopub.status.busy":"2022-11-13T00:42:12.299108Z","iopub.status.idle":"2022-11-13T00:42:12.314839Z","shell.execute_reply":"2022-11-13T00:42:12.313720Z","shell.execute_reply.started":"2022-11-13T00:42:12.299387Z"},"papermill":{"duration":0.023513,"end_time":"2022-11-02T12:05:43.873346","exception":false,"start_time":"2022-11-02T12:05:43.849833","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_df = train_df.reset_index().drop(columns = ['index'], axis = 1)\n","valid_df = valid_df.reset_index().drop(columns = ['index'], axis = 1)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008042,"end_time":"2022-11-02T12:05:43.889628","exception":false,"start_time":"2022-11-02T12:05:43.881586","status":"completed"},"tags":[]},"source":["## 3. Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:12.316712Z","iopub.status.busy":"2022-11-13T00:42:12.316352Z","iopub.status.idle":"2022-11-13T00:42:12.327123Z","shell.execute_reply":"2022-11-13T00:42:12.325984Z","shell.execute_reply.started":"2022-11-13T00:42:12.316677Z"},"papermill":{"duration":0.020153,"end_time":"2022-11-02T12:05:43.917979","exception":false,"start_time":"2022-11-02T12:05:43.897826","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["## Creating the dataset\n","\n","class RVLCDIPData(Dataset):\n","    \n","    def __init__(self, image_list, label_list, target_size, tokenizer, max_len = 512, transform = None):\n","        \n","        self.image_list = image_list\n","        self.label_list = label_list\n","        self.target_size = target_size\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.image_list)\n","    \n","    def __getitem__(self, idx):\n","        img_path = self.image_list[idx]\n","        label = self.label_list[idx]\n","        \n","        ## More on this, in the repo mentioned previously\n","        final_encoding = create_features(\n","            img_path,\n","            self.tokenizer,\n","            add_batch_dim=False,\n","            target_size=self.target_size,\n","            max_seq_length=self.max_len,\n","            path_to_save=None,\n","            save_to_disk=False,\n","            apply_mask_for_mlm=False,\n","            extras_for_debugging=False,\n","            use_ocr = True\n","    )\n","        if self.transform is not None:\n","            ## Note that, ToTensor is already applied on the image\n","            final_encoding['resized_scaled_img'] = self.transform(final_encoding['resized_scaled_img'])\n","        \n","        \n","        keys_to_reshape = ['x_features', 'y_features', 'resized_and_aligned_bounding_boxes']\n","        for key in keys_to_reshape:\n","            final_encoding[key] = final_encoding[key][:self.max_len]\n","            \n","        final_encoding['label'] = torch.as_tensor(label).long()\n","        return final_encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:12.329519Z","iopub.status.busy":"2022-11-13T00:42:12.328432Z","iopub.status.idle":"2022-11-13T00:42:16.692895Z","shell.execute_reply":"2022-11-13T00:42:16.691820Z","shell.execute_reply.started":"2022-11-13T00:42:12.329481Z"},"papermill":{"duration":5.975954,"end_time":"2022-11-02T12:05:49.902389","exception":false,"start_time":"2022-11-02T12:05:43.926435","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["## Defining the tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:16.694995Z","iopub.status.busy":"2022-11-13T00:42:16.694334Z","iopub.status.idle":"2022-11-13T00:42:16.700425Z","shell.execute_reply":"2022-11-13T00:42:16.699355Z","shell.execute_reply.started":"2022-11-13T00:42:16.694952Z"},"papermill":{"duration":0.017229,"end_time":"2022-11-02T12:05:49.929413","exception":false,"start_time":"2022-11-02T12:05:49.912184","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from torchvision import transforms\n","\n","## Normalization to these mean and std (I have seen some tutorials used this, and also in image reconstruction, so used it)\n","transform = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                              "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:16.702744Z","iopub.status.busy":"2022-11-13T00:42:16.702070Z","iopub.status.idle":"2022-11-13T00:42:16.712915Z","shell.execute_reply":"2022-11-13T00:42:16.711989Z","shell.execute_reply.started":"2022-11-13T00:42:16.702706Z"},"papermill":{"duration":0.018557,"end_time":"2022-11-02T12:05:49.957365","exception":false,"start_time":"2022-11-02T12:05:49.938808","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_ds = RVLCDIPData(train_df['img'].tolist(), train_df['label'].tolist(),\n","                      target_size, tokenizer, config['max_position_embeddings'], transform)\n","val_ds = RVLCDIPData(valid_df['img'].tolist(), valid_df['label'].tolist(),\n","                      target_size, tokenizer,config['max_position_embeddings'],  transform)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.019029,"end_time":"2022-11-02T12:05:49.991204","exception":false,"start_time":"2022-11-02T12:05:49.972175","status":"completed"},"tags":[]},"source":["### Collate Function:\n","\n","Definitely collate function is an amazing function for using the dataloader as per our wish. More on collate function can be known from [here](https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:16.715141Z","iopub.status.busy":"2022-11-13T00:42:16.714713Z","iopub.status.idle":"2022-11-13T00:42:16.725021Z","shell.execute_reply":"2022-11-13T00:42:16.723981Z","shell.execute_reply.started":"2022-11-13T00:42:16.715097Z"},"papermill":{"duration":0.038782,"end_time":"2022-11-02T12:05:50.051728","exception":false,"start_time":"2022-11-02T12:05:50.012946","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def collate_fn(data_bunch):\n","\n","  dict_data_bunch = {}\n","\n","  for i in data_bunch:\n","    for (key, value) in i.items():\n","      if key not in dict_data_bunch:\n","        dict_data_bunch[key] = []\n","      dict_data_bunch[key].append(value)\n","\n","  for key in list(dict_data_bunch.keys()):\n","      dict_data_bunch[key] = torch.stack(dict_data_bunch[key], axis = 0)\n","\n","  return dict_data_bunch"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.015803,"end_time":"2022-11-02T12:05:50.085877","exception":false,"start_time":"2022-11-02T12:05:50.070074","status":"completed"},"tags":[]},"source":["## 4. Defining the DataModule\n","\n","* A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data:\n","\n","* A DataModule is simply a collection of a train_dataloader(s), val_dataloader(s), test_dataloader(s) and predict_dataloader(s) along with the matching transforms and data processing/downloads steps required.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:16.727053Z","iopub.status.busy":"2022-11-13T00:42:16.726633Z","iopub.status.idle":"2022-11-13T00:42:18.019451Z","shell.execute_reply":"2022-11-13T00:42:18.018471Z","shell.execute_reply.started":"2022-11-13T00:42:16.727018Z"},"papermill":{"duration":1.272604,"end_time":"2022-11-02T12:05:51.374520","exception":false,"start_time":"2022-11-02T12:05:50.101916","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pytorch_lightning as pl\n","\n","class DataModule(pl.LightningDataModule):\n","\n","  def __init__(self, train_dataset, val_dataset,  batch_size = 4):\n","\n","    super(DataModule, self).__init__()\n","    self.train_dataset = train_dataset\n","    self.val_dataset = val_dataset\n","    self.batch_size = batch_size\n","\n","  def train_dataloader(self):\n","    return DataLoader(self.train_dataset, batch_size = self.batch_size, \n","                      collate_fn = collate_fn, shuffle = True)\n","  \n","  def val_dataloader(self):\n","    return DataLoader(self.val_dataset, batch_size = self.batch_size,\n","                                  collate_fn = collate_fn, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:18.021879Z","iopub.status.busy":"2022-11-13T00:42:18.021210Z","iopub.status.idle":"2022-11-13T00:42:18.027522Z","shell.execute_reply":"2022-11-13T00:42:18.026464Z","shell.execute_reply.started":"2022-11-13T00:42:18.021839Z"},"papermill":{"duration":0.016912,"end_time":"2022-11-02T12:05:51.401342","exception":false,"start_time":"2022-11-02T12:05:51.384430","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["datamodule = DataModule(train_ds, val_ds)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00882,"end_time":"2022-11-02T12:05:51.419256","exception":false,"start_time":"2022-11-02T12:05:51.410436","status":"completed"},"tags":[]},"source":["## 5. Model\n","\n","1. Firstly, we would define the pytorch model with our configurations, in which the class labels would be ranging from 0 to 15\n","2. Secondly, we would encode it in the PyTorch Lightening module, and boom 💥 our work of defining the model is done"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:18.029791Z","iopub.status.busy":"2022-11-13T00:42:18.029259Z","iopub.status.idle":"2022-11-13T00:42:18.039907Z","shell.execute_reply":"2022-11-13T00:42:18.038874Z","shell.execute_reply.started":"2022-11-13T00:42:18.029753Z"},"papermill":{"duration":0.021634,"end_time":"2022-11-02T12:05:51.449976","exception":false,"start_time":"2022-11-02T12:05:51.428342","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class DocFormerForClassification(nn.Module):\n","  \n","    def __init__(self, config):\n","      super(DocFormerForClassification, self).__init__()\n","\n","      self.resnet = ResNetFeatureExtractor(hidden_dim = config['max_position_embeddings'])\n","      self.embeddings = DocFormerEmbeddings(config)\n","      self.lang_emb = LanguageFeatureExtractor()\n","      self.config = config\n","      self.dropout = nn.Dropout(config['hidden_dropout_prob'])\n","      self.linear_layer = nn.Linear(in_features = config['hidden_size'], out_features = len(id2label))  ## Number of Classes\n","      self.encoder = DocFormerEncoder(config)\n","\n","    def forward(self, batch_dict):\n","\n","      x_feat = batch_dict['x_features']\n","      y_feat = batch_dict['y_features']\n","\n","      token = batch_dict['input_ids']\n","      img = batch_dict['resized_scaled_img']\n","\n","      v_bar_s, t_bar_s = self.embeddings(x_feat,y_feat)\n","      v_bar = self.resnet(img)\n","      t_bar = self.lang_emb(token)\n","      out = self.encoder(t_bar,v_bar,t_bar_s,v_bar_s)\n","      out = self.linear_layer(out)\n","      out = out[:, 0, :]\n","      return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:18.041694Z","iopub.status.busy":"2022-11-13T00:42:18.041270Z","iopub.status.idle":"2022-11-13T00:42:18.116071Z","shell.execute_reply":"2022-11-13T00:42:18.115203Z","shell.execute_reply.started":"2022-11-13T00:42:18.041657Z"},"papermill":{"duration":0.084571,"end_time":"2022-11-02T12:05:51.543743","exception":false,"start_time":"2022-11-02T12:05:51.459172","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["## Defining pytorch lightning model\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import torchmetrics\n","\n","class DocFormer(pl.LightningModule):\n","\n","  def __init__(self, config , lr = 5e-5):\n","    super(DocFormer, self).__init__()\n","    \n","    self.save_hyperparameters()\n","    self.config = config\n","    self.docformer = DocFormerForClassification(config)\n","    \n","    self.num_classes = len(id2label)\n","    self.train_accuracy_metric = torchmetrics.Accuracy()\n","    self.val_accuracy_metric = torchmetrics.Accuracy()\n","    self.f1_metric = torchmetrics.F1Score(num_classes=self.num_classes)\n","    self.precision_macro_metric = torchmetrics.Precision(\n","            average=\"macro\", num_classes=self.num_classes\n","        )\n","    self.recall_macro_metric = torchmetrics.Recall(\n","            average=\"macro\", num_classes=self.num_classes\n","        )\n","    self.precision_micro_metric = torchmetrics.Precision(average=\"micro\")\n","    self.recall_micro_metric = torchmetrics.Recall(average=\"micro\")\n","\n","  def forward(self, batch_dict):\n","    logits = self.docformer(batch_dict)\n","    return logits\n","\n","  def training_step(self, batch, batch_idx):\n","    logits = self.forward(batch)\n","\n","    loss = nn.CrossEntropyLoss()(logits, batch['label'])\n","    preds = torch.argmax(logits, 1)\n","\n","    ## Calculating the accuracy score\n","    train_acc = self.train_accuracy_metric(preds, batch[\"label\"])\n","\n","    ## Logging\n","    self.log('train/loss', loss,prog_bar = True, on_epoch=True, logger=True, on_step=True)\n","    self.log('train/acc', train_acc, prog_bar = True, on_epoch=True, logger=True, on_step=True)\n","\n","    return loss\n","  \n","  def validation_step(self, batch, batch_idx):\n","    logits = self.forward(batch)\n","    loss = nn.CrossEntropyLoss()(logits, batch['label'])\n","    preds = torch.argmax(logits, 1)\n","    \n","    labels = batch['label']\n","    # Metrics\n","    valid_acc = self.val_accuracy_metric(preds, labels)\n","    precision_macro = self.precision_macro_metric(preds, labels)\n","    recall_macro = self.recall_macro_metric(preds, labels)\n","    precision_micro = self.precision_micro_metric(preds, labels)\n","    recall_micro = self.recall_micro_metric(preds, labels)\n","    f1 = self.f1_metric(preds, labels)\n","\n","    # Logging metrics\n","    self.log(\"valid/loss\", loss, prog_bar=True, on_step=True, logger=True)\n","    self.log(\"valid/acc\", valid_acc, prog_bar=True, on_epoch=True, logger=True, on_step=True)\n","    self.log(\"valid/precision_macro\", precision_macro, prog_bar=True, on_epoch=True, logger=True, on_step=True)\n","    self.log(\"valid/recall_macro\", recall_macro, prog_bar=True, on_epoch=True, logger=True, on_step=True)\n","    self.log(\"valid/precision_micro\", precision_micro, prog_bar=True, on_epoch=True, logger=True, on_step=True)\n","    self.log(\"valid/recall_micro\", recall_micro, prog_bar=True, on_epoch=True, logger=True, on_step=True)\n","    self.log(\"valid/f1\", f1, prog_bar=True, on_epoch=True)\n","    \n","    return {\"label\": batch['label'], \"logits\": logits}\n","\n","  def validation_epoch_end(self, outputs):\n","        labels = torch.cat([x[\"label\"] for x in outputs])\n","        logits = torch.cat([x[\"logits\"] for x in outputs])\n","        preds = torch.argmax(logits, 1)\n","\n","        wandb.log({\"cm\": wandb.sklearn.plot_confusion_matrix(labels.cpu().numpy(), preds.cpu().numpy())})\n","        self.logger.experiment.log(\n","            {\"roc\": wandb.plot.roc_curve(labels.cpu().numpy(), logits.cpu().numpy())}\n","        )\n","        \n","  def configure_optimizers(self):\n","    return torch.optim.AdamW(self.parameters(), lr = self.hparams['lr'])"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008852,"end_time":"2022-11-02T12:05:51.562026","exception":false,"start_time":"2022-11-02T12:05:51.553174","status":"completed"},"tags":[]},"source":["## 6. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:18.117790Z","iopub.status.busy":"2022-11-13T00:42:18.117349Z","iopub.status.idle":"2022-11-13T00:42:18.126481Z","shell.execute_reply":"2022-11-13T00:42:18.125376Z","shell.execute_reply.started":"2022-11-13T00:42:18.117747Z"},"trusted":true},"outputs":[],"source":["from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.loggers import WandbLogger\n","\n","def main():\n","    datamodule = DataModule(train_ds, val_ds)\n","    docformer = DocFormer.load_from_checkpoint('../input/chkpnt9/epoch9.ckpt')\n","\n","    checkpoint_callback = ModelCheckpoint(\n","        dirpath=\"./checkpoints/\", monitor=\"valid/loss\", mode=\"min\"\n","    )\n","    early_stopping_callback = EarlyStopping(\n","        monitor=\"valid/loss\", patience=3, verbose=True, mode=\"min\"\n","    )\n","    \n","    wandb.init(config=config, project=\"RVL CDIP with DocFormer New Version\")\n","    wandb_logger = WandbLogger(project=\"RVL CDIP with DocFormer New Version\", entity=\"udit_amin\")\n","    ## https://www.tutorialexample.com/implement-reproducibility-in-pytorch-lightning-pytorch-lightning-tutorial/\n","    pl.seed_everything(seed, workers=True)\n","    trainer = pl.Trainer(\n","        accelerator='gpu', devices=1,\n","        default_root_dir=\"logs\",\n","        max_epochs=1,\n","        fast_dev_run=False,\n","        logger=wandb_logger,\n","        callbacks=[checkpoint_callback, early_stopping_callback],\n","        deterministic=True\n","    )\n","    trainer.fit(docformer, datamodule)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:18.128393Z","iopub.status.busy":"2022-11-13T00:42:18.128019Z","iopub.status.idle":"2022-11-13T00:42:18.139220Z","shell.execute_reply":"2022-11-13T00:42:18.137938Z","shell.execute_reply.started":"2022-11-13T00:42:18.128360Z"},"papermill":{"duration":0.016438,"end_time":"2022-11-02T12:05:51.616692","exception":false,"start_time":"2022-11-02T12:05:51.600254","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","os.mkdir(\"/kaggle/working/checkpoints\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-13T00:42:18.141269Z","iopub.status.busy":"2022-11-13T00:42:18.140862Z","iopub.status.idle":"2022-11-13T01:34:10.556550Z","shell.execute_reply":"2022-11-13T01:34:10.555251Z","shell.execute_reply.started":"2022-11-13T00:42:18.141215Z"},"papermill":{"duration":10824.947244,"end_time":"2022-11-02T15:06:16.573006","exception":false,"start_time":"2022-11-02T12:05:51.625762","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
